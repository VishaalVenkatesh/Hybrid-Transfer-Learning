{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Vishaal\\\\Documents\\\\GitHub\\\\Hybrid-Transfer-Learning\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Generic Module Imports \n",
    "\n",
    "'''\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Pennylane is an open source quantum machine learning package by Xanadu. Pennylane also allows to use IBMs Qiskit as an\n",
    "    installed plugin. We may or may not evntually use that.\n",
    "    \n",
    "    Citation: \n",
    "    Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Carsten Blank, Keri McKiernan and Nathan Killoran. \n",
    "    PennyLane. arXiv, 2018. arXiv:1811.04968\n",
    "'''\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np # Same as standard numpy, but also does automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    PyTorch is an open-source machine learning library by Facebook. It is similar to Tensorflow by Google. It's pretty \n",
    "    cool to use this to build models and import pre-trained neural nets like ResNet18. \n",
    "    \n",
    "    PyTorch uses torch tensors and not numpy arrays. We may have to convert as and when necesary. \n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn                    #This serves as a base class for neural networks (NNs)#\n",
    "import torch.optim as optim              #Contains built-in optimizer functions - like Stochastic Gradient Descent(SGD) & Adam Optimizer'''\n",
    "from torch.optim import lr_scheduler     #Helps modulate learning rate based on number of epochs\n",
    "import torchvision                       #PyTorchs imgage datasets and other related stuff\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    Initialize Some Parameters - For now we will use an integrated Pennylane Device. This is sort of a simulator for \n",
    "    a quantum computer. I will later attempt to use a real Quantum Computer using IBMs Q Experience but no guarantees. \n",
    "    This should not technically affect our results. Because we only use 4 qubits, the quantum simulator should have no \n",
    "    issues accurately simulating the process in polyomial time. Problems will arise for ~>50 qubits.\n",
    "    \n",
    "'''\n",
    "n_qubits = 4              # Number of qubits\n",
    "step = 0.0004               # Learning rate\n",
    "batch_size = 4             # Number of samples for each training step. This is the number of features taken in from ResNet18.\n",
    "num_epochs = 30            # Number of training epochs. Set to 1 to train quickly. We will later change this to 30\n",
    "q_depth = 6                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "rng_seed = 0                # Seed for random number generator\n",
    "start_time = time.time()    # Start of the computation timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Initialize the quantum device. Two options for names are Default & Gaussian. Shots is the number of times the circuit \n",
    "    will be run. 1024 or 2^10 is generally a good number. Wires is the number of modes to intialise the qubits in. \n",
    "    Remember qubits have a probabilistic nature and can take up various states. \n",
    "'''\n",
    "dev = qml.device(name = 'default.qubit', shots = 1024, wires = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Cuda is a parallel computing architecture created by Nvidia. The following line of code is to check if you have a GPU \n",
    "    in your computer and use it. Else, the CPU will be used.\n",
    "'''\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Directory for image data. Note the dataset is relatively small with only 250 images. We cannot train a whole classical\n",
    "    or quantum CNN using such small data. However, because we are using transfer learning this would suffice to do some\n",
    "    additional training. \n",
    "'''\n",
    "data_dir = \"..\\\\Data\\\\hymenoptera_data\"\n",
    "\n",
    "'''\n",
    "    Create a dictionary of transforms we need to do to the image data. For both the training and validation set.\n",
    "    Note: the values for normalise are the mean and std of the images in ImageNet (256 X 256 X 3).  \n",
    "'''\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Establish the training and validation image datasets. This is the torchvision method of loading data.\n",
    "'''\n",
    "image_datasets = {\n",
    "    x if x == \"train\" else \"validation\": datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in [\"train\", \"val\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    244 training images and 153 validation images in two different classes ants and bees\n",
    "'''\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Initialize the data loader. We don't load the data yet.\n",
    "'''\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size = batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"validation\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Define a function to plot the images as they get ready\n",
    "'''\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    '''\n",
    "        Invert the normalisation we did before\n",
    "    '''\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    The Hadamard gate applies to a single qubit in state 0 or state 1. Once applied it results in superposition and\n",
    "    gives a 50% for state 0 or state 1 to exist. Basically - gives qubits their quantum nature.\n",
    "    https://en.wikipedia.org/wiki/Quantum_logic_gate#Hadamard_(H)_gate\n",
    "'''\n",
    "\n",
    "def H_layer(nqubits):\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "        \n",
    "'''\n",
    "    Rotates a single qubit by theta radians along the y-axis. w is a list of angles in radians you want to rotate each\n",
    "    qubit by\n",
    "    https://www.quantum-inspire.com/kbase/ry-gate/\n",
    "    https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RY.html\n",
    "'''        \n",
    "def RY_layer(w):\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "        \n",
    "'''\n",
    "    This is the controlled-not operator. The CNOT gate operates on two qubits at a time. For example, if the first qubit is\n",
    "    in state 1, the second one is flipped two. In other words, the state of the second qubit depends on the state of the \n",
    "    first one. This is kinda what quantum entanglement is. Einstein called it spooky phenomenon and although we have \n",
    "    experimental proof, we yet don't have conclusive mathematical proof from first principles to prove this. \n",
    "'''\n",
    "def entangling_layer(nqubits):\n",
    "    for i in range(0, nqubits - 1, 2):  \n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  \n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "'''\n",
    "    Designing the Variational Quantum Circuit - There are three steps innvolved...\n",
    "    1. Embedding - Qubits are initialised in superimposed state. They are then rotated across to input parameters.\n",
    "    2. Variational Layers - A sequence of trainable rotation layers and constant entangling layers is applied.\n",
    "    3. Measurement - For each qubit, the expectation of the angular momentum (Z) operator is measured. This has to be done\n",
    "                     using a classical bit which can then be processed. *Most quantum phenomenon has to be measured using\n",
    "                     a classical bit. This is similar to the Schrodinger's cat experiment where quanutum phenomenon is \n",
    "                     maintined till a measurement is made. \n",
    "'''\n",
    "'''\n",
    "    When applied to a quantum function, it turns it into a QNode instance. Because, interface is set as torch, the input and \n",
    "    output have to be torch tensors. Interface can also be set to TensorFlow.\n",
    "''' \n",
    "@qml.qnode(dev, interface = 'torch')\n",
    "\n",
    "def quantum_network(q_input_features, q_weights_flat):\n",
    "    q_weights = q_weights_flat.reshape(q_depth, n_qubits)\n",
    "    H_layer(n_qubits)\n",
    "    '''\n",
    "        Embedding\n",
    "    '''\n",
    "    RY_layer(q_input_features)\n",
    "    '''\n",
    "        Variational Layers\n",
    "    '''\n",
    "    for k in range(q_depth):\n",
    "        entangling_layer(n_qubits)\n",
    "        RY_layer(q_weights[k])\n",
    "    '''\n",
    "        Measuring Expectation - PauliZ operator applies a phase flip. PauliX is bit flip.PauliY does both.\n",
    "    '''\n",
    "    exp_vals = [qml.expval(qml.PauliZ(position)) for position in range(n_qubits)]\n",
    "    return tuple(exp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    A dressed quantum circuit with classical pre-processing and post-processing layers\n",
    "'''\n",
    "class DressedQuantumNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.pre_net = nn.Linear(512, n_qubits)\n",
    "        self.q_params = nn.Parameter(q_delta * torch.randn(q_depth * n_qubits))\n",
    "        self.post_net = nn.Linear(n_qubits, 2)\n",
    "\n",
    "    def forward(self, input_features):\n",
    "        # obtain the input features for the quantum circuit\n",
    "        # by reducing the feature dimension from 512 to 4\n",
    "        pre_out = self.pre_net(input_features)\n",
    "        q_in = torch.tanh(pre_out) * np.pi / 2.0\n",
    "\n",
    "        # Apply the quantum circuit to each element of the batch and append to q_out\n",
    "        q_out = torch.Tensor(0, n_qubits)\n",
    "        q_out = q_out.to(device)\n",
    "        for elem in q_in:\n",
    "            q_out_elem = quantum_network(elem, self.q_params).float().unsqueeze(0)\n",
    "            q_out = torch.cat((q_out, q_out_elem))\n",
    "\n",
    "        # return the two-dimensional prediction from the postprocessing layer\n",
    "        return self.post_net(q_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Creating a hybrid NN using ResNet18 and the dressed quantum circuit...\n",
    "    \n",
    "'''\n",
    "model_hybrid = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_hybrid.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "# Notice that model_hybrid.fc is the last layer of ResNet18\n",
    "model_hybrid.fc = DressedQuantumNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We use cross entropy as the loss function\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We use an Adam optimizer that updates the weights of our model at each step of the process. It is a derivation\n",
    "    of Stohasti Gradient Descent (SGD) but differs in that it has a a per-parameter adaptive learning rate that depends\n",
    "    on the average of the magnitiude of recent gradiets i.e. how fast it it changing. It can provide good results fast\n",
    "    but is not always the best as SGD sometimes finds better solutions. \n",
    "'''\n",
    "optimizer_hybrid = optim.Adam(model_hybrid.fc.parameters(), lr=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We schedule to reduce the learning rate by a factor of gamma_lr_scheduler every 10 epochs\n",
    "'''\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_hybrid, step_size=7, gamma=gamma_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Training function\n",
    "'''\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 10000.0  # Large arbitrary number\n",
    "    best_acc_train = 0.0\n",
    "    best_loss_train = 10000.0  # Large arbitrary number\n",
    "    proba = []\n",
    "    print(\"Training started:\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"validation\"]:\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            n_batches = dataset_sizes[phase] // batch_size\n",
    "            it = 0\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                since_batch = time.time()\n",
    "                batch_size_ = len(inputs)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Track/compute gradient and make an optimization step only when training\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    #_ seems to have the probabilities. preds is the actual output 0/1\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'validation':\n",
    "                        \n",
    "                        proba.append(_)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Print iteration results\n",
    "                running_loss += loss.item() * batch_size_\n",
    "                batch_corrects = torch.sum(preds == labels.data).item()\n",
    "                running_corrects += batch_corrects\n",
    "                print(\n",
    "                    \"Phase: {} Epoch: {}/{} Iter: {}/{} Batch time: {:.4f}\".format(\n",
    "                        phase,\n",
    "                        epoch + 1,\n",
    "                        num_epochs,\n",
    "                        it + 1,\n",
    "                        n_batches + 1,\n",
    "                        time.time() - since_batch,\n",
    "                    ),\n",
    "                    end=\"\\r\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                it += 1\n",
    "\n",
    "            # Print epoch results\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print(\n",
    "                \"Phase: {} Epoch: {}/{} Loss: {:.4f} Acc: {:.4f}        \".format(\n",
    "                    \"train\" if phase == \"train\" else \"validation  \",\n",
    "                    epoch + 1,\n",
    "                    num_epochs,\n",
    "                    epoch_loss,\n",
    "                    epoch_acc,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Check if this is the best model wrt previous epochs\n",
    "            if phase == \"validation\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == \"validation\" and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "            if phase == \"train\" and epoch_acc > best_acc_train:\n",
    "                best_acc_train = epoch_acc\n",
    "            if phase == \"train\" and epoch_loss < best_loss_train:\n",
    "                best_loss_train = epoch_loss\n",
    "\n",
    "    # Print final results\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(\"Best test loss: {:.4f} | Best test accuracy: {:.4f}\".format(best_loss, best_acc))\n",
    "    return (model, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishaal\\Anaconda3_Mod\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase: train Epoch: 1/30 Loss: 0.6246 Acc: 0.6844        \n",
      "Phase: validation   Epoch: 1/30 Loss: 0.5555 Acc: 0.7582        \n",
      "Phase: train Epoch: 2/30 Loss: 0.5846 Acc: 0.7008        \n",
      "Phase: validation   Epoch: 2/30 Loss: 0.4765 Acc: 0.8627        \n",
      "Phase: train Epoch: 3/30 Loss: 0.5272 Acc: 0.7910        \n",
      "Phase: validation   Epoch: 3/30 Loss: 0.4391 Acc: 0.8758        \n",
      "Phase: train Epoch: 4/30 Loss: 0.5203 Acc: 0.7787        \n",
      "Phase: validation   Epoch: 4/30 Loss: 0.3927 Acc: 0.8758        \n",
      "Phase: train Epoch: 5/30 Loss: 0.4152 Acc: 0.8484        \n",
      "Phase: validation   Epoch: 5/30 Loss: 0.3769 Acc: 0.9216        \n",
      "Phase: train Epoch: 6/30 Loss: 0.4119 Acc: 0.8607        \n",
      "Phase: validation   Epoch: 6/30 Loss: 0.3170 Acc: 0.9281        \n",
      "Phase: train Epoch: 7/30 Loss: 0.3995 Acc: 0.8648        \n",
      "Phase: validation   Epoch: 7/30 Loss: 0.3252 Acc: 0.9085        \n",
      "Phase: train Epoch: 8/30 Loss: 0.4095 Acc: 0.8607        \n",
      "Phase: validation   Epoch: 8/30 Loss: 0.3061 Acc: 0.9412        \n",
      "Phase: train Epoch: 9/30 Loss: 0.4119 Acc: 0.8238        \n",
      "Phase: validation   Epoch: 9/30 Loss: 0.3067 Acc: 0.9412        \n",
      "Phase: train Epoch: 10/30 Loss: 0.3590 Acc: 0.8689        \n",
      "Phase: validation   Epoch: 10/30 Loss: 0.3196 Acc: 0.9150        \n",
      "Phase: train Epoch: 11/30 Loss: 0.4075 Acc: 0.8279        \n",
      "Phase: validation   Epoch: 11/30 Loss: 0.3041 Acc: 0.9412        \n",
      "Phase: train Epoch: 12/30 Loss: 0.4067 Acc: 0.8566        \n",
      "Phase: validation   Epoch: 12/30 Loss: 0.3040 Acc: 0.9281        \n",
      "Phase: train Epoch: 13/30 Loss: 0.3906 Acc: 0.8484        \n",
      "Phase: validation   Epoch: 13/30 Loss: 0.3030 Acc: 0.9542        \n",
      "Phase: train Epoch: 14/30 Loss: 0.4023 Acc: 0.8361        \n",
      "Phase: validation   Epoch: 14/30 Loss: 0.2959 Acc: 0.9281        \n",
      "Phase: train Epoch: 15/30 Loss: 0.4161 Acc: 0.8279        \n",
      "Phase: validation   Epoch: 15/30 Loss: 0.3017 Acc: 0.9281        \n",
      "Phase: train Epoch: 16/30 Loss: 0.3658 Acc: 0.8811        \n",
      "Phase: validation   Epoch: 16/30 Loss: 0.3007 Acc: 0.9608        \n",
      "Phase: train Epoch: 17/30 Loss: 0.4028 Acc: 0.8730        \n",
      "Phase: validation   Epoch: 17/30 Loss: 0.3080 Acc: 0.9542        \n",
      "Phase: train Epoch: 18/30 Loss: 0.4010 Acc: 0.8484        \n",
      "Phase: validation   Epoch: 18/30 Loss: 0.2977 Acc: 0.9477        \n",
      "Phase: train Epoch: 19/30 Loss: 0.4279 Acc: 0.8279        \n",
      "Phase: validation   Epoch: 19/30 Loss: 0.3585 Acc: 0.8954        \n",
      "Phase: train Epoch: 20/30 Loss: 0.4008 Acc: 0.8279        \n",
      "Phase: validation   Epoch: 20/30 Loss: 0.3009 Acc: 0.9542        \n",
      "Phase: train Epoch: 21/30 Loss: 0.3772 Acc: 0.8607        \n",
      "Phase: validation   Epoch: 21/30 Loss: 0.3109 Acc: 0.9085        \n",
      "Phase: train Epoch: 22/30 Loss: 0.3821 Acc: 0.8730        \n",
      "Phase: validation   Epoch: 22/30 Loss: 0.3007 Acc: 0.9150        \n",
      "Phase: train Epoch: 23/30 Loss: 0.3438 Acc: 0.8893        \n",
      "Phase: validation   Epoch: 23/30 Loss: 0.2973 Acc: 0.9477        \n",
      "Phase: train Epoch: 24/30 Loss: 0.4022 Acc: 0.8402        \n",
      "Phase: validation   Epoch: 24/30 Loss: 0.2974 Acc: 0.9412        \n",
      "Phase: train Epoch: 25/30 Loss: 0.3714 Acc: 0.8730        \n",
      "Phase: validation   Epoch: 25/30 Loss: 0.2965 Acc: 0.9608        \n",
      "Phase: train Epoch: 26/30 Loss: 0.3999 Acc: 0.8484        \n",
      "Phase: validation   Epoch: 26/30 Loss: 0.2972 Acc: 0.9542        \n",
      "Phase: train Epoch: 27/30 Loss: 0.4075 Acc: 0.8402        \n",
      "Phase: validation   Epoch: 27/30 Loss: 0.3010 Acc: 0.9477        \n",
      "Phase: train Epoch: 28/30 Loss: 0.3846 Acc: 0.8648        \n",
      "Phase: validation   Epoch: 28/30 Loss: 0.2976 Acc: 0.9412        \n",
      "Phase: train Epoch: 29/30 Loss: 0.3838 Acc: 0.8730        \n",
      "Phase: validation   Epoch: 29/30 Loss: 0.3000 Acc: 0.9281        \n",
      "Phase: train Epoch: 30/30 Loss: 0.3665 Acc: 0.8893        \n",
      "Phase: validation   Epoch: 30/30 Loss: 0.2973 Acc: 0.9477        \n",
      "Training completed in 139m 26s\n",
      "Best test loss: 0.2959 | Best test accuracy: 0.9608\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Training our model\n",
    "'''\n",
    "model_hybrid, p = train_model(model_hybrid, criterion, optimizer_hybrid, exp_lr_scheduler, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishaal\\Anaconda3_Mod\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model_hybrid.eval()\n",
    "#real label\n",
    "y = []\n",
    "#scores. Calculate our pred using this\n",
    "scores = []\n",
    "for i, (inputs, labels) in enumerate(dataloaders['validation']):\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model_hybrid(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    sm = torch.nn.Softmax()\n",
    "    probabilities = sm(outputs) \n",
    "    \n",
    "    for j in range(len(labels.tolist())):\n",
    "        y.append(labels.tolist()[j])\n",
    "        scores.append(probabilities.tolist()[j][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(len(scores))\n",
    "for i in range(len(scores)):\n",
    "    if scores[i] >= 0.5:\n",
    "        a[i] = 1\n",
    "    else:\n",
    "        a[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "  \n",
    "# Calling DataFrame constructor after zipping \n",
    "# both lists, with columns specified \n",
    "df = pd.DataFrame(list(zip(y, scores, a)), \n",
    "               columns =['True Label', 'Score', 'Predicted Label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C://Users//Vishaal//Documents//GitHub//Hybrid-Transfer-Learning//Report//Quantum_Validation_Scores.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axarr = plt.subplots(1,1, figsize=(15, 8),constrained_layout=True)\n",
    "fig.suptitle(\"ROC Curves\", fontsize=18)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, scores)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "axarr.set_title('ROC - My MLP', fontsize=12)\n",
    "axarr.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "axarr.legend(loc = 'right', fontsize=20)\n",
    "axarr.plot([0, 1], [0, 1],'r--')\n",
    "axarr.set_xlim([0, 1])\n",
    "axarr.set_ylim([0, 1])\n",
    "axarr.set_ylabel('True Positive Rate', fontsize=12)\n",
    "axarr.set_xlabel('False Positive Rate', fontsize=12)\n",
    "plt.savefig('C://Users//Vishaal//Documents//GitHub//Hybrid-Transfer-Learning//Plots//Quantum_ROC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_train_loss = [0.6246, 0.5846, 0.5272, 0.5203, 0.4152, 0.4119, 0.3995, 0.4095, 0.4119, 0.359,\n",
    "                 0.4075, 0.4067, 0.3906, 0.4023, 0.4161, 0.3658, 0.4028, 0.401,  0.4279, 0.4008,\n",
    "                 0.3772, 0.3821, 0.3438, 0.4022, 0.3714, 0.3999, 0.4075, 0.3846, 0.3838, 0.3665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_val_loss = [0.5555, 0.4765, 0.4391, 0.3927, 0.3769, 0.317,  0.3252, 0.3061, 0.3067, 0.3196,\n",
    "               0.3041, 0.304,  0.303,  0.2959, 0.3017, 0.3007, 0.308,  0.2977, 0.3585, 0.3009,\n",
    "               0.3109, 0.3007, 0.2973, 0.2974, 0.2965, 0.2972, 0.301,  0.2976, 0.3,    0.2973]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
