{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Vishaal\\\\Documents\\\\GitHub\\\\Hybrid-Transfer-Learning\\\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Generic Module Imports \n",
    "\n",
    "'''\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Pennylane is an open source quantum machine learning package by Xanadu. Pennylane also allows to use IBMs Qisklit as an\n",
    "    installed plugin. We may or may not evntually use that.\n",
    "    \n",
    "    Citation: \n",
    "    Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Carsten Blank, Keri McKiernan and Nathan Killoran. \n",
    "    PennyLane. arXiv, 2018. arXiv:1811.04968\n",
    "'''\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np # Same as standard numpy, but also does automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    PyTorch is an open-source machine learning library by Facebook. It is similar to Tensorflow by Google. It's pretty \n",
    "    cool to use this to build models and import pre-trained neural nets like ResNet18. \n",
    "    \n",
    "    PyTorch uses torch tensors and not numpy arrays. We may have to convert as and when necesary. \n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn                    #This serves as a base class for neural networks (NNs)#\n",
    "import torch.optim as optim              #Contains built-in optimizer functions - like Stochastic Gradient Descent(SGD) & Adam Optimizer'''\n",
    "from torch.optim import lr_scheduler     #Helps modulate learning rate based on number of epochs\n",
    "import torchvision                       #PyTorchs imgage datasets and other related stuff\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    Initialize Some Parameters - For now we will use an integrated Pennylane Device. This is sort of a simulator for \n",
    "    a quantum computer. I will later attempt to use a real Quantum Computer using IBMs Q Experience but no guarantees. \n",
    "    This should not technically affect our results. Because we only use 4 qubits, the quantum simulator should have no \n",
    "    issues accurately simulating the process in polyomial time. Problems will arise for ~>50 qubits.\n",
    "    \n",
    "'''\n",
    "n_qubits = 4                # Number of qubits\n",
    "step = 0.0004               # Learning rate\n",
    "batch_size = 4              # Number of samples for each training step. This is the number of features taken in from ResNet18.\n",
    "num_epochs = 1              # Number of training epochs. Set to 1 to train quickly. We will later change this to 30\n",
    "q_depth = 6                 # Depth of the quantum circuit (number of variational layers)\n",
    "gamma_lr_scheduler = 0.1    # Learning rate reduction applied every 10 epochs.\n",
    "q_delta = 0.01              # Initial spread of random quantum weights\n",
    "rng_seed = 0                # Seed for random number generator\n",
    "start_time = time.time()    # Start of the computation timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Initialize the quantum device. Two options for names are Default & Gaussian. Shots is the number of times the circuit \n",
    "    will be run. 1024 or 2^10 is generally a good number. Wires is the number of modes to intialise the qubits in. \n",
    "    Remember qubits have a probabilistic nature and can take up various states. \n",
    "'''\n",
    "dev = qml.device(name = 'default.qubit', shots = 1024, wires = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Cuda is a parallel computing architecture created by Nvidia. The following line of code is to check if you have a GPU \n",
    "    in your computer and use it. Else, the CPU will be used.\n",
    "'''\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Directory for image data. Note the dataset is relatively small with only 250 images. We cannot train a whole classical\n",
    "    or quantum CNN using such small data. However, because we are using transfer learning this would suffice to do some\n",
    "    additional training. \n",
    "'''\n",
    "data_dir = \"..\\\\Data\\\\hymenoptera_data\\\\hymenoptera_data\"\n",
    "\n",
    "'''\n",
    "    Create a dictionary of transforms we need to do to the image data. For both the training and validation set.\n",
    "    Note: the values for normalise are the mean and std of the images in ImageNet (256 X 256 X 3).  \n",
    "'''\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Establish the training and validation image datasets. This is the torchvision method of loading data.\n",
    "'''\n",
    "image_datasets = {\n",
    "    x if x == \"train\" else \"validation\": datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in [\"train\", \"val\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    244 training images and 153 validation images in two different classes ants and bees\n",
    "'''\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"validation\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Initialize the data loader. We don't load the data yet.\n",
    "'''\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True)\n",
    "    for x in [\"train\", \"validation\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Define a function to plot the images as they get ready\n",
    "'''\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    '''\n",
    "        Invert the normalisation we did before\n",
    "    '''\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Designing the Variational Quantum Circuit\n",
    "'''\n",
    "'''\n",
    "    The Hadamard gate applies to a single qubit in state 0 or state 1. Once applied it results in superposition and\n",
    "    gives a 50% for state 0 or state 1 to exist. Basically - gives qubits their quantum nature.\n",
    "    https://en.wikipedia.org/wiki/Quantum_logic_gate#Hadamard_(H)_gate\n",
    "'''\n",
    "\n",
    "def H_layer(nqubits):\n",
    "    for idx in range(nqubits):\n",
    "        qml.Hadamard(wires=idx)\n",
    "        \n",
    "'''\n",
    "    Rotates a single qubit by theta radians along the y-axis. w is a list of angles in radians you want to rotate each\n",
    "    qubit by\n",
    "    https://www.quantum-inspire.com/kbase/ry-gate/\n",
    "    https://pennylane.readthedocs.io/en/stable/code/api/pennylane.RY.html\n",
    "'''        \n",
    "def RY_layer(w):\n",
    "    for idx, element in enumerate(w):\n",
    "        qml.RY(element, wires=idx)\n",
    "        \n",
    "'''\n",
    "    This is the controlled-not operator. The CNOT gate operates on two qubits at a time. For example, if the first qubit is\n",
    "    in state 1, the second one is flipped two. In other words, the state of the second qubit depends on the state of the \n",
    "    first one. This is kinda what quantum entanglement is. Einstein called it spooky phenomenon and although we have \n",
    "    experimental proof, we yet don't have conclusive mathematical proof from first principles to prove this. \n",
    "'''\n",
    "def entangling_layer(nqubits):\n",
    "    for i in range(0, nqubits - 1, 2):  \n",
    "        qml.CNOT(wires=[i, i + 1])\n",
    "    for i in range(1, nqubits - 1, 2):  \n",
    "        qml.CNOT(wires=[i, i + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
